[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "emova"
version = "1.0.0"
description = "Empowering Language Models to See, Hear and Speak with Vivid Emotions"
readme = "README.md"
requires-python = ">=3.9"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: Apache Software License",
]
dependencies = [
    # install torch first
    "torch==2.4.0", "torchvision==0.19.0", "deepspeed==0.14.4",
    "transformers==4.47.1", "tokenizers",
    "attrdict",
    "sentencepiece==0.1.99",  #SentencePiece==0.1.96
    "shortuuid",
    "accelerate==0.33.0", "peft==0.4.0", "bitsandbytes",
    "pydantic==1.10.13", "markdown2[all]", "numpy", "scikit-learn==1.2.2",
    "requests", "httpx==0.24.0", "uvicorn", "fastapi",
    "einops==0.6.1", "einops-exts==0.0.4",
    "timm==0.9.12", "tensorboardX", "tiktoken",
    "loguru",
]

[project.optional-dependencies]
npu = [
    "pyyaml", "numpy==1.23.5", "decorator", "scipy", "attrs", "psutil",
    "torch_npu==2.4.0", 
]
train = ["ninja", "wandb"]
build = ["build", "twine"]
gradio = ["gradio==4.44.0", "pydantic==2.9.2"]
speech = [
    "pandas", "monotonic_align", 
    "librosa==0.8.0", "phonemizer", 
    "unidecode", "hydra-core==1.3.2", "pytorch_lightning==1.1.0",
    "wget", "wrapt", "onnx", "frozendict", "inflect", "braceexpand",
    "webdataset", "torch_stft", "sox", "editdistance", "numpy==1.23.5", "protobuf==3.20",
    "datasets", "funasr", "torchaudio==2.0.2", "pydub", "onnxconverter_common",
    "cffi==1.16.0", "openai"
]

[project.urls]
"Homepage" = "https://emova-ollm.github.io/"
"Bug Tracker" = "https://github.com/emova-ollm/EMOVA/issues"

[tool.setuptools.packages.find]
exclude = ["assets*", "benchmark*", "docs", "dist*", "playground*", "scripts*", "tests*"]

[tool.wheel]
exclude = ["assets*", "benchmark*", "docs", "dist*", "playground*", "scripts*", "tests*"]
